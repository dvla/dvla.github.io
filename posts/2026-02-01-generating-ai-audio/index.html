<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Generating AI Audio | DVLA Engineering</title><meta name=keywords content="AI,Generative AI,Audio,Accessibility"><meta name=description content="Exploring the use of Generative AI to create accessible and engaging audio content from long-form documents"><meta name=author content="Gethin James"><link rel=canonical href=https://dvla.github.io/posts/2026-02-01-generating-ai-audio/><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://dvla.github.io/favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dvla.github.io/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dvla.github.io/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://dvla.github.io/favicon/apple-touch-icon.png><link rel=mask-icon href=https://dvla.github.io/favicon/favicon-16x16.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://dvla.github.io/posts/2026-02-01-generating-ai-audio/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-WH4N9FEEE8"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-WH4N9FEEE8")}</script><meta property="og:url" content="https://dvla.github.io/posts/2026-02-01-generating-ai-audio/"><meta property="og:site_name" content="DVLA Engineering"><meta property="og:title" content="Generating AI Audio"><meta property="og:description" content="Exploring the use of Generative AI to create accessible and engaging audio content from long-form documents"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-01T00:00:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="Generative AI"><meta property="article:tag" content="Audio"><meta property="article:tag" content="Accessibility"><meta property="og:image" content="https://dvla.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dvla.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Generating AI Audio"><meta name=twitter:description content="Exploring the use of Generative AI to create accessible and engaging audio content from long-form documents"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dvla.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Generating AI Audio","item":"https://dvla.github.io/posts/2026-02-01-generating-ai-audio/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Generating AI Audio","name":"Generating AI Audio","description":"Exploring the use of Generative AI to create accessible and engaging audio content from long-form documents","keywords":["AI","Generative AI","Audio","Accessibility"],"articleBody":"You may prefer to listen to the audio version of this blog post.\nAt the DVLA Emerging Technology Lab, we wondered whether Generative AI could be used to make long-form documents more accessible and engaging.\nMany individuals find reading extensive written documents challenging. Recent technological advances have enabled the generation of “audio overviews” and “podcasts” from text content. Our idea was to explore how far this technology might assist neurodiverse individuals, or those for whom English is not a first language.\nAs a government agency, we are committed to ensuring that content is handled securely and remains accessible only to authorised staff within the agency. To achieve this, we created a Microsoft Teams Bot called “Audry”. Audry allows a user to upload a document and automatically transform it into a podcast or news briefing. We wanted to produce audio that features authentic regional UK accents.\nAudry Teams Bot\nAgentic Review Many advances in Generative AI have originated in the United States, resulting in some technology displaying a US bias. For example, generated transcripts occasionally contained American expressions that are unsuitable for a UK audience, such as “DMV” instead of “DVLA”. To address this, we adopted an agentic approach to reviewing the transcript. Using LangGraph, we created three personas to review the transcript, and a fourth expert to edit it based on the feedback.\nAgentic Review Process\nBritish Expert: Assessed grammar and verified the use of appropriate British cultural references. Content Reviewer: Moderated content for compliance with UK government standards. Expressive Delivery Advisor (think Drama teacher): Suggested emotional and non-verbal sound cues. (For example, adding pauses or varying tone.) Editor: Incorporated feedback from the previous three experts and rewrote the transcript accordingly. Challenges There has been a significant improvement in voice quality due to recent advances. However, accessing the latest multi-speaker voice models remains difficult. These models are often still in preview stages and provide limited support for British English. Achieving consistent voice generation is challenging. Submitting the same parameters to a large language model (LLM) does not always produce identical results. While this makes generative AI powerful, it also impedes reliable and repeatable voice outputs. We experimented with dividing large transcripts (5 mins+) into smaller requests. However, combining these segments often resulted in noticeable changes in the voices during conversations. Regional accents can be influenced through specific prompts, for example requesting a Welsh or Scottish accent. In our experience, this approach was not consistently reliable. Further work is needed to create uniform regional accents. Technology Here are some of the technologies we used:\nMicrosoft Teams AI and Bot Framework Azure Document Intelligence, Cosmos DB, Speech Service, App Service Google Gemini 2.5-flash and Text-to-Speech (TTS) models Eleven Labs Text-to-Speech API LangGraph for agentic review Conclusions This technology is still emerging, and producing consistently accurate regional British audio content remains a challenge. However, the technology may already be sufficiently usable. This podcast was generated by uploading this blog post through our system. You can decide for yourself if we succeeded.\nFollowing Government Service Standards, the code for Audry is open source.\n","wordCount":"509","inLanguage":"en","image":"https://dvla.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2026-01-01T00:00:00Z","dateModified":"2026-01-01T00:00:00Z","author":{"@type":"Person","name":"Gethin James"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dvla.github.io/posts/2026-02-01-generating-ai-audio/"},"publisher":{"@type":"Organization","name":"DVLA Engineering","logo":{"@type":"ImageObject","url":"https://dvla.github.io/favicon/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dvla.github.io/ accesskey=h title="DVLA Engineering (Alt + H)"><img src=https://dvla.github.io/favicon/apple-touch-icon.png alt aria-label=logo height=49>DVLA Engineering</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dvla.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://dvla.github.io/open-source/ title=Open-source><span>Open-source</span></a></li><li><a href=https://github.com/dvla/ title=Github><span>Github</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://www.civil-service-careers.gov.uk/departments/working-for-the-driver-and-vehicle-licensing-agency/ title=Careers><span>Careers</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dvla.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://dvla.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Generating AI Audio</h1><div class=post-description>Exploring the use of Generative AI to create accessible and engaging audio content from long-form documents</div><div class=post-meta><span title='2026-01-01 00:00:00 +0000 UTC'>January 1, 2026</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;509 words&nbsp;·&nbsp;Gethin James</div></header><div class=post-content><p><a href=audio_podcast.mp3>You may prefer to listen to the audio version of this blog post.</a></p><p>At the DVLA Emerging Technology Lab, we wondered whether Generative AI could be used to make long-form documents more accessible and engaging.</p><p>Many individuals find reading extensive written documents challenging. Recent technological advances have enabled the generation of &ldquo;audio overviews&rdquo; and &ldquo;podcasts&rdquo; from text content. Our idea was to explore how far this technology might assist neurodiverse individuals, or those for whom English is not a first language.</p><p>As a government agency, we are committed to ensuring that content is handled securely and remains accessible only to authorised staff within the agency. To achieve this, we created a Microsoft Teams Bot called &ldquo;Audry&rdquo;. Audry allows a user to upload a document and automatically transform it into a podcast or news briefing. We wanted to produce audio that features authentic regional UK accents.</p><figure class=align-center><img loading=lazy src=audry.png#center alt="Audry Teams Bot"><figcaption><p>Audry Teams Bot</p></figcaption></figure><h2 id=agentic-review>Agentic Review<a hidden class=anchor aria-hidden=true href=#agentic-review>#</a></h2><p>Many advances in Generative AI have originated in the United States, resulting in some technology displaying a US bias. For example, generated transcripts occasionally contained American expressions that are unsuitable for a UK audience, such as &ldquo;DMV&rdquo; instead of &ldquo;DVLA&rdquo;. To address this, we adopted an agentic approach to reviewing the transcript. Using <a href=https://www.langchain.com/langgraph>LangGraph</a>, we created three personas to review the transcript, and a fourth expert to edit it based on the feedback.</p><figure><img loading=lazy src=agentic_edit_diagram.png alt="Agentic Review Process"><figcaption><p>Agentic Review Process</p></figcaption></figure><ul><li>British Expert: Assessed grammar and verified the use of appropriate British cultural references.</li><li>Content Reviewer: Moderated content for compliance with UK government standards.</li><li>Expressive Delivery Advisor (think Drama teacher): Suggested emotional and non-verbal sound cues. (For example, adding pauses or varying tone.)</li><li>Editor: Incorporated feedback from the previous three experts and rewrote the transcript accordingly.</li></ul><h2 id=challenges>Challenges<a hidden class=anchor aria-hidden=true href=#challenges>#</a></h2><ul><li>There has been a significant improvement in voice quality due to recent advances. However, accessing the latest multi-speaker voice models remains difficult. These models are often still in preview stages and provide limited support for British English.</li><li>Achieving consistent voice generation is challenging. Submitting the same parameters to a large language model (LLM) does not always produce identical results. While this makes generative AI powerful, it also impedes reliable and repeatable voice outputs. We experimented with dividing large transcripts (5 mins+) into smaller requests. However, combining these segments often resulted in noticeable changes in the voices during conversations.</li><li>Regional accents can be influenced through specific prompts, for example requesting a Welsh or Scottish accent. In our experience, this approach was not consistently reliable. Further work is needed to create uniform regional accents.</li></ul><h2 id=technology>Technology<a hidden class=anchor aria-hidden=true href=#technology>#</a></h2><p>Here are some of the technologies we used:</p><ul><li>Microsoft Teams AI and Bot Framework</li><li>Azure Document Intelligence, Cosmos DB, Speech Service, App Service</li><li>Google Gemini 2.5-flash and Text-to-Speech (TTS) models</li><li>Eleven Labs Text-to-Speech API</li><li>LangGraph for agentic review</li></ul><h2 id=conclusions>Conclusions<a hidden class=anchor aria-hidden=true href=#conclusions>#</a></h2><p>This technology is still emerging, and producing consistently accurate regional British audio content remains a challenge. However, the technology may already be sufficiently usable. <a href=audio_podcast.mp3>This podcast was generated by uploading this blog post through our system</a>. You can decide for yourself if we succeeded.</p><p>Following Government Service Standards, the <a href=https://github.com/dvla/audry>code for Audry is open source</a>.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://dvla.github.io/tags/ai/>AI</a></li><li><a href=https://dvla.github.io/tags/generative-ai/>Generative AI</a></li><li><a href=https://dvla.github.io/tags/audio/>Audio</a></li><li><a href=https://dvla.github.io/tags/accessibility/>Accessibility</a></li></ul><nav class=paginav><a class=next href=https://dvla.github.io/posts/2025-06-09-double-splat-nil/><span class=title>Next »</span><br><span>TiL: Double Splat Nil in Ruby</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://dvla.github.io/>DVLA Engineering</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>